{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from colorama import init, Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init(autoreset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    \"meta.llama3-70b-instruct-v1:0\", #Big Llama\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\", #Big Claude\n",
    "    \"anthropic.claude-3-5-sonnet-20240620-v1:0\", #Last Claude\n",
    "    \"anthropic.claude-3-sonnet-20240229-v1:0\", #Last middle Claude\n",
    "    \"mistral.mixtral-8x7b-instruct-v0:1\", #Big Mistral\n",
    "    \"meta.llama3-8b-instruct-v1:0\" #Small Llama\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"Devuelve solo el texto original con la identificación y etiquetación del texto con la información personal del paciente añadiendolo entre claudators, por ejemplo: [**arquitecto**], [**8/9/21**], [**padre**]. No comentes nada más\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poner -> Etiquetas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meddocan = \"\"\"\n",
    "Nombres\n",
    "Datos geográficos\n",
    "Todos los elementos de las fechas\n",
    "Números telefónicos\n",
    "Números FAX\n",
    "Correos electrónicos\n",
    "Números de Seguridad Social\n",
    "Números de registros médicos\n",
    "Números de beneficiarios del plan de salud\n",
    "Números de cuenta11.Certificado / números de licencia\n",
    "Identificadores de vehículos y números de serie, incluidas placas\n",
    "Identificadores de dispositivo y números de serie\n",
    "URL web\n",
    "Direcciones de protocolo de Interne\n",
    "Identificadores biométricos (es decir, escaneo retiniano, huellas dactilar\n",
    "Fotos de cara completa e imágenes comparable\n",
    "Cualquier número de identificación único, característica o código\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an anonimization tool in identifying attributes in texts that can identify or quasi-identify a user.\"),\n",
    "    (\"user\", \"{prompt1} {text} {meddocan}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_and_masked_carmen(name):\n",
    "    filename = f'./data/processed/txt/{name}'\n",
    "    filename_result = f'./data/processed/masked/{name}'\n",
    "    with open(filename, 'r') as archivo:\n",
    "        text = archivo.read()\n",
    "\n",
    "    with open(filename_result, 'r') as archivo:\n",
    "        text_masked = archivo.read()\n",
    "\n",
    "    return [text, text_masked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data  = []\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "llm_small_llama =   ChatBedrock(  \n",
    "                            model_id=MODELS[5],\n",
    "                            region_name='eu-west-2',\n",
    "                            model_kwargs=dict(temperature=0.1),\n",
    "                    )\n",
    "llm_big_llama   =   ChatBedrock(    \n",
    "                            model_id=MODELS[0],\n",
    "                            region_name='eu-west-2',\n",
    "                            model_kwargs=dict(temperature=0.1),\n",
    "                    )\n",
    "llm_haiku       =   ChatBedrock(    \n",
    "                            model_id=MODELS[1],\n",
    "                            region_name='eu-west-3',\n",
    "                            model_kwargs=dict(temperature=0.1),\n",
    "                    )\n",
    "llm_sonet       =   ChatBedrock(    \n",
    "                            model_id=MODELS[3],\n",
    "                            region_name='eu-west-3',\n",
    "                            model_kwargs=dict(temperature=0.1),\n",
    "                    )\n",
    "llm_mistral     =   ChatBedrock(\n",
    "                        model_id=MODELS[4],\n",
    "                        region_name='eu-west-2',\n",
    "                        model_kwargs=dict(temperature=0.1)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(filename, text):\n",
    "    with open(filename, 'w') as archivo:\n",
    "        archivo.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(name):\n",
    "    try:\n",
    "        os.mkdir(name)\n",
    "        print(f\"Folder '{name}' created successfully\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating the folder '{name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonimized(llm=None, name_model=\"\"):\n",
    "    counter = 0\n",
    "    path = './data/processed/txt'\n",
    "    chain = prompt_template | llm | parser\n",
    "    for filename in os.listdir(path):\n",
    "        [text, text_hoped] = get_text_and_masked_carmen(filename)\n",
    "        text_new = chain.invoke({\"prompt1\":prompt1, \"text\": text, \"meddocan\": meddocan})\n",
    "        create_folder(f'data/anon/raw/{name_model}')\n",
    "        save_file(f'data/anon/raw/{name_model}/{filename}', text_new)\n",
    "        counter += 1\n",
    "        if counter > 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_small_llama = threading.Thread(target=anonimized, args=(llm_small_llama, \"small_llama\" ))\n",
    "thread_big_llama = threading.Thread(target=anonimized, args=(llm_big_llama, \"big_llama\" ))\n",
    "thread_haiku = threading.Thread(target=anonimized, args=(llm_haiku, \"haiku\" ))\n",
    "thread_sonet = threading.Thread(target=anonimized, args=(llm_sonet, \"sonet\" ))\n",
    "thread_mistral = threading.Thread(target=anonimized, args=(llm_mistral, \"mistral\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'data/anon/raw/haiku' created successfully\n",
      "Folder 'data/anon/raw/small_llama' created successfully\n",
      "Folder 'data/anon/raw/sonet' created successfully\n",
      "Folder 'data/anon/raw/big_llama' created successfully\n",
      "Folder 'data/anon/raw/sonet' created successfully\n"
     ]
    }
   ],
   "source": [
    "thread_small_llama.start()\n",
    "thread_big_llama.start()\n",
    "thread_haiku.start()\n",
    "thread_sonet.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
