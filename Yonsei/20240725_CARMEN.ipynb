{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cf52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from openai import OpenAI\n",
    "from dateutil import parser\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pymssql\n",
    "from threading import Thread\n",
    "import functools\n",
    "import difflib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "with open('openai_apikey.txt', 'r') as file:\n",
    "    apikey = file.read()\n",
    "os.environ[\"OPENAI_API_KEY\"] = apikey\n",
    "\n",
    "def calc_metrics(ground_truth, predictions):\n",
    "    ground_truth_counter = Counter(ground_truth)\n",
    "    predictions_counter = Counter(predictions)\n",
    "\n",
    "    true_positives = sum((ground_truth_counter & predictions_counter).values())\n",
    "    false_positives = sum((predictions_counter - ground_truth_counter).values())\n",
    "    false_negatives = sum((ground_truth_counter - predictions_counter).values())\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def evaluate(masked, generated):\n",
    "    \"\"\" \n",
    "    Input: \n",
    "        - masked (str): Ground_truth text\n",
    "        - generated(str): Text to be evaluated\n",
    "\n",
    "    Output:\n",
    "        - Precision, Recall and F1 (float)\n",
    "    \"\"\"\n",
    "    ground_truth = re.findall(r'\\[\\*\\*(.*?)\\*\\*\\]', masked)\n",
    "    predictions = re.findall(r'\\[\\*\\*(.*?)\\*\\*\\]', generated)\n",
    "    #print(ground_truth)\n",
    "    #print(predictions)\n",
    "    \n",
    "    return calc_metrics(ground_truth, predictions)\n",
    "\n",
    "def levenshtein_distance(s1, s2, show_progress=True):\n",
    "    \"\"\"\n",
    "    Calcula la distancia de Levenshtein entre dos cadenas.\n",
    "\n",
    "    La distancia de Levenshtein es el número mínimo de operaciones de edición \n",
    "    (inserción, eliminación o sustitución de un carácter) necesarias para \n",
    "    transformar una cadena en otra.\n",
    "\n",
    "    Parámetros:\n",
    "        s1 (str): Primera cadena\n",
    "        s2 (str): Segunda cadena\n",
    "        show_progress (bool): Si es True, muestra una barra de progreso. \n",
    "                              Por defecto es False.\n",
    "    Retorna:\n",
    "        int: La distancia de Levenshtein entre s1 y s2\n",
    "    \"\"\"\n",
    "    # Usar tqdm solo si show_progress es True\n",
    "    iterable = tqdm(s1) if show_progress else s1\n",
    "\n",
    "    if len(s1) < len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = list(range(len(s2) + 1))\n",
    "    for i, c1 in enumerate(iterable):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "def get_cos_sim(text_hoped, text_generated):\n",
    "    vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w[\\w\\-/]*\\b\")\n",
    "    tfidf_matrix = vectorizer.fit_transform([text_hoped, text_generated])\n",
    "\n",
    "    try:\n",
    "        cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    except: \n",
    "        return 0.0\n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "def replace_special_characters(text):\n",
    "    # Define the pattern to match special characters including . / and -\n",
    "    pattern = r'[!@#$%^&*()_+={}\\[\\]:;\"\\'<>,?\\\\|`~./-]'\n",
    "    \n",
    "    # Replace the matched characters with a space\n",
    "    result = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def find_indices(text, word):\n",
    "    \"\"\"Find all indices of word in text\"\"\"\n",
    "    return [m.start() for m in re.finditer(re.escape(word), text)]\n",
    "\n",
    "\n",
    "def replace_nth_occurrence(text, word, n):\n",
    "    \"\"\"Replace the nth occurrence of word in text with [**word**]\"\"\"\n",
    "    indices = find_indices(text, word)\n",
    "    if n < len(indices):\n",
    "        start_index = indices[n]\n",
    "        end_index = start_index + len(word)\n",
    "        text = text[:start_index] + '[**' + word + '**]' + text[end_index:]\n",
    "    return text\n",
    "\n",
    "\n",
    "def sort_by_length_descending(str_list):\n",
    "    return sorted(str_list, key=len, reverse=True)\n",
    "\n",
    "def process_text(text):\n",
    "    result = []\n",
    "    stack = []\n",
    "    i = 0\n",
    "    n = len(text)\n",
    "\n",
    "    while i < n:\n",
    "        if text[i:i+3] == '[**':\n",
    "            if not stack:\n",
    "                result.append('[**')\n",
    "            stack.append('[**')\n",
    "            i += 3\n",
    "        elif text[i:i+3] == '**]':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "            if not stack:\n",
    "                result.append('**]')\n",
    "            i += 3\n",
    "        else:\n",
    "            result.append(text[i])\n",
    "            i += 1\n",
    "\n",
    "    return ''.join(result)\n",
    "\n",
    "def prediction_process(Prediction, Replaced):\n",
    "    # Extract all words enclosed in [** **] in the Prediction text\n",
    "    enclosed_words = re.findall(r'\\[\\*\\*(.*?)\\*\\*\\]', Prediction)\n",
    "    enclosed_words = list(set(enclosed_words))\n",
    "    enclosed_words = sort_by_length_descending(enclosed_words)\n",
    "    \n",
    "    # Create a copy of Replaced text to apply changes\n",
    "    updated_replaced = Replaced\n",
    "\n",
    "    for word in enclosed_words:\n",
    "        # Find all indices of the word in the Prediction text\n",
    "        prediction_indices = find_indices(Prediction, '[**' + word + '**]')\n",
    "        \n",
    "        # Replace the nth occurrence of word in Replaced text based on the indices in Prediction\n",
    "        for idx in range(len(prediction_indices)):\n",
    "            updated_replaced = replace_nth_occurrence(updated_replaced, word, idx)\n",
    "            \n",
    "    updated_replaced=process_text(updated_replaced)\n",
    "\n",
    "    return updated_replaced\n",
    "\n",
    "'''\n",
    "def partial_score(X, Y):\n",
    "    if X in Y or Y in X:\n",
    "        x_words = X.split()\n",
    "        y_words = Y.split()\n",
    "\n",
    "        matches = sum(1 for word in y_words if word in x_words)\n",
    "\n",
    "        return matches / len(x_words) if len(x_words) > 0 else 0\n",
    "    else:\n",
    "        return 0\n",
    "'''\n",
    "\n",
    "def partial_score(X, Y):\n",
    "    if X in Y or Y in X:\n",
    "        x_words = X.split()\n",
    "        y_words = Y.split()\n",
    "\n",
    "        counter_a1 = Counter(x_words)\n",
    "        counter_a2 = Counter(y_words)\n",
    "\n",
    "        matches = 0\n",
    "\n",
    "        for element in counter_a1:\n",
    "            if element in counter_a2:\n",
    "\n",
    "                matches += min(counter_a1[element], counter_a2[element])\n",
    "\n",
    "        return matches / len(x_words) if len(x_words) > 0 else 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def evaluate2(masked,generated):\n",
    "    masked=masked.replace('\\n','')\n",
    "    generated=generated.replace('\\n','')\n",
    "\n",
    "    ground_truth_matches = re.finditer(r'\\[\\*\\*(.*?)\\*\\*\\]', masked)\n",
    "    ground_truth_positions = {}\n",
    "    cnt=0\n",
    "    for match in ground_truth_matches:\n",
    "        start = match.start(1)-(cnt*2+1)*3  # start of the group (excluding [**)\n",
    "        end = match.end(1)-(cnt*2+1)*3\n",
    "        cnt+=1# end of the group (excluding **])\n",
    "        ground_truth_positions[(start, end)] = replace_special_characters(match.group(1))\n",
    "\n",
    "    predictions_matches = re.finditer(r'\\[\\*\\*(.*?)\\*\\*\\]', generated)\n",
    "    predictions_positions = {}\n",
    "    cnt=0\n",
    "    for match in predictions_matches:\n",
    "        start = match.start(1)-(cnt*2+1)*3  # start of the group (excluding [**)\n",
    "        end = match.end(1)-(cnt*2+1)*3\n",
    "        cnt+=1# end of the group (excluding **])\n",
    "        predictions_positions[(start, end)] = replace_special_characters(match.group(1))\n",
    "\n",
    "    totalwordcnt_ground_truth = len(ground_truth_positions)\n",
    "    score_total=0\n",
    "    for pos_g in ground_truth_positions:\n",
    "        for pos_p in predictions_positions:\n",
    "            if (pos_p[0]<=pos_g[0] and pos_p[1]>=pos_g[1]) or (pos_p[0]>=pos_g[0] and pos_p[1]<=pos_g[1]):\n",
    "                score_temp = partial_score(ground_truth_positions[pos_g],predictions_positions[pos_p])\n",
    "                score_total += score_temp\n",
    "\n",
    "    score_total = score_total/totalwordcnt_ground_truth\n",
    "    recall = score_total\n",
    "\n",
    "    totalwordcnt_predictions = len(predictions_positions)\n",
    "    score_total=0\n",
    "    for pos_p in predictions_positions:\n",
    "        for pos_g in ground_truth_positions:\n",
    "            if (pos_g[0]<=pos_p[0] and pos_g[1]>=pos_p[1]) or (pos_g[0]>=pos_p[0] and pos_g[1]<=pos_p[1]):\n",
    "                score_temp = partial_score(predictions_positions[pos_p],ground_truth_positions[pos_g])\n",
    "                score_total += score_temp\n",
    "\n",
    "    score_total = score_total/totalwordcnt_predictions\n",
    "    precision = score_total\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "#ARMEN_base_path='CARMEN-I_v1.01b 2/CARMEN-I_v1.01b/txt/'\n",
    "CARMEN_base_path='data/data/processed/'\n",
    "\n",
    "txtlist=os.listdir(CARMEN_base_path+'masked/')\n",
    "\n",
    "# This is for connecting to the MSSQL server via pymssql. Adjust it according to your configuration.\n",
    "conn = pymssql.connect(host=r\"(local)\", database='Ddrive5', charset='utf8')\n",
    "\n",
    "# This is the table name that you will create in the MSSQL server to save the GPT responses.\n",
    "# Adjust it according to your preferences.\n",
    "newtablename='20240725_test_Prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5db7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txtlist length 1539\n",
      "0\n",
      "556\n",
      "557\n",
      "559\n",
      "560\n",
      "1045\n",
      "1057\n",
      "1163\n",
      "1356\n",
      "length 1530\n"
     ]
    }
   ],
   "source": [
    "print('txtlist length',len(txtlist))\n",
    "\n",
    "df=pd.DataFrame(columns=['txtname','Replaced','Masked'])\n",
    "#for i in range(10): \n",
    "for i in range(len(txtlist)): \n",
    "    with open(CARMEN_base_path+'txt/'+txtlist[i], 'r', encoding='utf-8') as file:\n",
    "        Replaced = file.read()\n",
    "        if Replaced[0]=='\\n':\n",
    "            Replaced=Replaced[1:]\n",
    "        if Replaced[-1]=='\\n':\n",
    "            Replaced=Replaced[:-1]\n",
    "    with open(CARMEN_base_path+'masked/'+txtlist[i], 'r', encoding='utf-8') as file:\n",
    "        Masked = file.read()\n",
    "        if Masked[0]=='\\n':\n",
    "            Masked=Masked[1:]\n",
    "        if Masked[-1]=='\\n':\n",
    "            Masked=Masked[:-1]\n",
    "    if len(Masked.replace('**]','').replace('[**',''))!=len(Replaced):\n",
    "        print(i)\n",
    "    else:\n",
    "        templist=[]\n",
    "        templist.append(txtlist[i])\n",
    "        templist.append(Replaced) \n",
    "        templist.append(Masked) \n",
    "        df.loc[len(df)]=templist\n",
    "print('length',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825afc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for newtablename in [newtablename]:\n",
    "    sql_createtable=\"CREATE TABLE [\" + newtablename +\"\"\"] \n",
    "    (\n",
    "        txtname    NVARCHAR(max),\n",
    "        txt   NVARCHAR(max),\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    conn = pymssql.connect(host=r\"(local)\", database='Ddrive5', charset='utf8')\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(sql_createtable)\n",
    "            conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38af45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeout(timeout):\n",
    "    def deco(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            res = [Exception('function [%s] timeout [%s seconds] exceeded!' % (func.__name__, timeout))]\n",
    "            def newFunc():\n",
    "                try:\n",
    "                    res[0] = func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    res[0] = e\n",
    "            t = Thread(target=newFunc)\n",
    "            t.daemon = True\n",
    "            try:\n",
    "                t.start()\n",
    "                t.join(timeout)\n",
    "            except Exception as je:\n",
    "                print ('error starting thread')\n",
    "                raise je\n",
    "            ret = res[0]\n",
    "            #if isinstance(ret, BaseException):\n",
    "            #    raise ret\n",
    "            return ret\n",
    "        return wrapper\n",
    "    return deco\n",
    "\n",
    "            \n",
    "@timeout(0.1)\n",
    "def SQL_Prediction(Replaced, txtname, system_content, model_ver, numbers, temperature_setting):\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=model_ver,\n",
    "        temperature=temperature_setting,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        (\"system\", system_content),\n",
    "        (\"human\", Replaced),\n",
    "    ]\n",
    "    ai_msg = llm.invoke(messages)\n",
    "    Prediction = ai_msg.content\n",
    "\n",
    "\n",
    "\n",
    "    conn = pymssql.connect(host=r\"(local)\", database='Ddrive5', charset='utf8')\n",
    "    sql = \"INSERT INTO [\" + newtablename+\"] (txtname, txt) VALUES (%s, %s)\"\n",
    "\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(sql, (txtname, Prediction))\n",
    "            conn.commit()\n",
    "\n",
    "system_content2='''You are an anonymization tool in identifying attributes in texts that can identify or quasi-identify a user.\n",
    "Return only the original text with the identification and labeling of the patient's personal information by adding it between [** and **].\n",
    "Following are attributes that you must anonymize.\n",
    "\n",
    "- Names\n",
    "Example:\n",
    "En seguimiento por Hematología Centro Médico Aspasia (Dra. Valvanera).   ->\n",
    "En seguimiento por Hematología [**Centro Médico Aspasia**] (Dra. [**Valvanera**]).\n",
    "\n",
    "- Ages\n",
    "Example: \n",
    "Varón de 41 años.   ->\n",
    "[**Varón**] de [**41 años**].\n",
    "\n",
    "- Sexes\n",
    "Example: \n",
    "Varón de 41 años.   ->\n",
    "[**Varón**] de [**41 años**].\n",
    "\n",
    "- Professions\n",
    "Example: \n",
    "Trabaja como profesor.   ->\n",
    "Trabaja como [**profesor**].\n",
    "\n",
    "- Relatives\n",
    "Example: \n",
    "Vive con suegro y 2 yernos.   ->\n",
    "Vive con [**suegro**] y 2 [**yernos**].\n",
    "\n",
    "- Dates\n",
    "Example: \n",
    "ha estado viviendo en el Centro desde septiembre de 2008.   ->\n",
    "ha estado viviendo en el [**Centro**] desde [**septiembre de 2008**].\n",
    "\n",
    "- Phone numbers\n",
    "Example: \n",
    "contactando con el siguiente número de teléfono +50 88 078 68 49.   ->\n",
    "contactando con el siguiente número de teléfono [**+50 88 078 68 49**].\n",
    "\n",
    "- Identification numbers\n",
    "Example:\n",
    "El paciente otorga su consentimiento informado para participar en el estudio del protocolo WYX/8408/5545.   ->\n",
    "El paciente otorga su consentimiento informado para participar en el estudio del protocolo [**WYX/8408/5545.**]\n",
    "\n",
    "- Institutions, hospitals, health centers, etc\n",
    "Example: \n",
    "En seguimiento por Hematología Centro Médico Aspasia (Dra. Valvanera).   ->\n",
    "En seguimiento por Hematología [**Centro Médico Aspasia**] (Dra. [**Valvanera**]).\n",
    "Example:\n",
    "Control en Centro Salud Mental Reyes Católicos.   ->\n",
    "Control en [**Centro Salud Mental Reyes Católicos**].\n",
    "\n",
    "- Countries, territories, streets, etc\n",
    "Example:\n",
    "nacido en la República Italiana.   ->\n",
    "nacido en la [**República Italiana**].\n",
    "Example:\n",
    "ha estado viviendo en el Centro desde septiembre de 2008.   ->\n",
    "ha estado viviendo en el [**Centro**] desde [**septiembre de 2008**].\n",
    "Example:\n",
    "la dirección es Calle de Victor Hugo 39.   ->\n",
    "la dirección es [**Calle de Victor Hugo 39**].\n",
    "\n",
    "- Website URLs\n",
    "participar a través del siguiente enlace: https://www.donarsang.gencat.cat/covid19.   ->\n",
    "participar a través del siguiente enlace: [**https://www.donarsang.gencat.cat/covid19**].\n",
    "\n",
    "- Other sensitive information such as races, ethnicities, sexual orientation, dietary preferences, etc\n",
    "Example:\n",
    "raça blanca   ->\n",
    "[**raça blanca**]\n",
    "Example:\n",
    "Hsh\n",
    "[**Hsh**]\n",
    "Example:\n",
    "Vegetarià\n",
    "[**Vegetarià**]\n",
    "\n",
    "Do not comment anything else.\n",
    "Besides the anonymized attributes, provide the rest of the text exactly the same, including special characters and \\n symbols.\n",
    "Do not correct any typos or spacing errors at your discretion.\n",
    "For example, if the time is written as 31/12/2000-0 9:20:00 with incorrect spacing, do not return it corrected as 31/12/2000-09:20:00.\n",
    "Also, for example, if FLUTICASONA + AZELA STINA4 is written with incorrect spacing, do not return it corrected as FLUTICASONA + AZELASTINA 4.\n",
    "Only focus on the anonymization tasks I have specified, and ignore any typos or spacing errors\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23deebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "775515fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(sample_size):\n",
    "    txtname=df['txtname'][i]\n",
    "    Replaced=df['Replaced'][i]\n",
    "    SQL_Prediction(Replaced, txtname, system_content2, 'gpt-4o', 1, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ce2a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_1708\\2238912890.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_SQL_Prediction = pd.read_sql(sql=sql_statement, con=conn)\n"
     ]
    }
   ],
   "source": [
    "conn = pymssql.connect(host=r\"(local)\", database='Ddrive5', charset='utf8')\n",
    "sql_statement=\"select * from [\"+ newtablename + \"]\"\n",
    "df_SQL_Prediction = pd.read_sql(sql=sql_statement, con=conn)\n",
    "print(len(df_SQL_Prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9115fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if len(df_SQL_Prediction)>=sample_size:\n",
    "        break\n",
    "    \n",
    "    for i in range(sample_size):\n",
    "        if df['txtname'][i] not in list(df_SQL_Prediction['txtname']):\n",
    "            txtname=df['txtname'][i]\n",
    "            Replaced=df['Replaced'][i]\n",
    "            SQL_Prediction(Replaced, txtname, system_content2, 'gpt-4o', 1, 1.0)\n",
    "            print('inserted')\n",
    "    time.sleep(60)\n",
    "    print('slept')\n",
    "    cnt=0\n",
    "    for i in range(sample_size):\n",
    "        if df['txtname'][i] not in list(df_SQL_Prediction['txtname']):\n",
    "            cnt+=1\n",
    "    if cnt==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "362c17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.merge(df,df_SQL_Prediction,left_on='txtname',right_on='txtname',how='inner')\n",
    "df2.columns=['txtname','Replaced','Masked','Prediction']\n",
    "df2['Prediction_processed'] = df2.apply(lambda row: prediction_process(row['Prediction'], row['Replaced']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72644ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "for i in range(len(df2)):\n",
    "    cal_met = evaluate2(df2['Masked'][i], df2['Prediction_processed'][i])\n",
    "    precision.append(cal_met[0])\n",
    "    recall.append(cal_met[1])\n",
    "    f1.append(cal_met[2])\n",
    "\n",
    "df2['precision']=precision\n",
    "df2['recall']=recall\n",
    "df2['f1']=f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b2035d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall avg 0.9506474505434536\n",
      "precision avg 0.853307532440383\n",
      "f1 avg 0.8886579579179444\n",
      "recall weighted avg 0.9306856675622006\n",
      "precision weighted avg 0.8802684813331083\n",
      "f1 weightedavg 0.8950961132986501\n"
     ]
    }
   ],
   "source": [
    "print('recall avg',np.mean(df2['recall']))\n",
    "print('precision avg',np.mean(df2['precision']))\n",
    "print('f1 avg',np.mean(df2['f1']))\n",
    "\n",
    "df2['masked_count'] = df2['Masked'].str.count(r'\\[\\*\\*')\n",
    "total_masked_count=np.sum(df2['masked_count'])\n",
    "total_recall=0\n",
    "total_precision=0\n",
    "total_f1=0\n",
    "for i in range(len(df2)):\n",
    "    total_recall+=df2['recall'][i]*df2['masked_count'][i]\n",
    "    total_precision+=df2['precision'][i]*df2['masked_count'][i]\n",
    "    total_f1+=df2['f1'][i]*df2['masked_count'][i]\n",
    "recall_weighted_avg = total_recall/total_masked_count\n",
    "precision_weighted_avg = total_precision/total_masked_count\n",
    "f1_weighted_avg = total_f1/total_masked_count\n",
    "print('recall weighted avg',recall_weighted_avg)\n",
    "print('precision weighted avg',precision_weighted_avg)\n",
    "print('f1 weightedavg',f1_weighted_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d736504e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "cos_list=[]\n",
    "lev_list=[]\n",
    "for i in range(sample_size):\n",
    "    cos = get_cos_sim(df2['Prediction_processed'][i],df2['Masked'][i])\n",
    "    lev = levenshtein_distance(df2['Prediction_processed'][i],df2['Masked'][i], show_progress=False)\n",
    "    cos_list.append(cos)\n",
    "    lev_list.append(lev)\n",
    "    print(i)\n",
    "    \n",
    "df2['cos']=cos_list\n",
    "df2['lev']=lev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b471a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('20240725_CARMEN_Results.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cee8f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "df2=pd.read_csv('20240725_CARMEN_Results.csv',encoding='utf-8')\n",
    "sample_size=len(df2)\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600ed7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txtname</th>\n",
       "      <th>Replaced</th>\n",
       "      <th>Masked</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Prediction_processed</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>masked_count</th>\n",
       "      <th>cos</th>\n",
       "      <th>lev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARMEN-I_CC_2.txt</td>\n",
       "      <td>Realizo llamada telefónica. Refiere buen desca...</td>\n",
       "      <td>Realizo llamada telefónica. Refiere buen desca...</td>\n",
       "      <td>Realizo llamada telefónica. Refiere buen desca...</td>\n",
       "      <td>Realizo llamada telefónica. Refiere buen desca...</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>20</td>\n",
       "      <td>0.999295</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CARMEN-I_CC_3.txt</td>\n",
       "      <td>Visita unidad del dolor. Ver informe de evoluc...</td>\n",
       "      <td>Visita unidad del dolor. Ver informe de evoluc...</td>\n",
       "      <td>Visita unidad del dolor. Ver informe de evoluc...</td>\n",
       "      <td>Visita unidad del dolor. Ver informe de evoluc...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CARMEN-I_CC_4.txt</td>\n",
       "      <td>Primera llamada HDOM COVID-19 POSITIVO\\n.\\nTra...</td>\n",
       "      <td>Primera llamada HDOM COVID-19 POSITIVO\\n.\\nTra...</td>\n",
       "      <td>Primera llamada HDOM COVID-19 POSITIVO.\\nTraba...</td>\n",
       "      <td>Primera llamada HDOM COVID-19 POSITIVO\\n.\\nTra...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CARMEN-I_CC_5.txt</td>\n",
       "      <td>Primera llamada HDOM COVID-19 POSITIVO\\nTrabaj...</td>\n",
       "      <td>Primera llamada HDOM COVID-19 POSITIVO\\nTrabaj...</td>\n",
       "      <td>Primera llamada HDOM COVID-19 POSITIVO\\nTrabaj...</td>\n",
       "      <td>Primera llamada HDOM COVID-19 POSITIVO\\nTrabaj...</td>\n",
       "      <td>0.827950</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.887604</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CARMEN-I_IA_ANTECEDENTES_1.txt</td>\n",
       "      <td>Varón de 79 años, sin alergias a medicamentos ...</td>\n",
       "      <td>[**Varón**] de [**79 años**], sin alergias a m...</td>\n",
       "      <td>[**Varón**] de [**79 años**], sin alergias a m...</td>\n",
       "      <td>[**Varón**] de [**79 años**], sin alergias a m...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CARMEN-I_IA_ANTECEDENTES_57.txt</td>\n",
       "      <td>Antecedentes personales:\\nNatural de Islas Fal...</td>\n",
       "      <td>Antecedentes personales:\\nNatural de [**Islas ...</td>\n",
       "      <td>Antecedentes personales:\\nNatural de [**Islas ...</td>\n",
       "      <td>Antecedentes personales:\\nNatural de [**Islas ...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CARMEN-I_IA_ANTECEDENTES_58.txt</td>\n",
       "      <td>Hombre de 63 años de edad, sin alergias medica...</td>\n",
       "      <td>[**Hombre**] de [**63 años**] de edad, sin ale...</td>\n",
       "      <td>[**Hombre**] de [**63 años**] de edad, sin ale...</td>\n",
       "      <td>[**Hombre**] de [**63 años**] de edad, sin ale...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CARMEN-I_IA_ANTECEDENTES_59.txt</td>\n",
       "      <td>Vive en residencia, cognitivamente preservada,...</td>\n",
       "      <td>Vive en residencia, cognitivamente preservada,...</td>\n",
       "      <td>Vive en residencia, cognitivamente preservada,...</td>\n",
       "      <td>Vive en residencia, cognitivamente preservada,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>CARMEN-I_IA_ANTECEDENTES_6.txt</td>\n",
       "      <td>Varón de 61 años, sin alergias medicamentosas ...</td>\n",
       "      <td>[**Varón**] de [**61 años**], sin alergias med...</td>\n",
       "      <td>[**Varón**] de [**61 años**], sin alergias med...</td>\n",
       "      <td>[**Varón**] de [**61 años**], sin alergias med...</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.908535</td>\n",
       "      <td>13</td>\n",
       "      <td>0.995160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CARMEN-I_IA_ANTECEDENTES_60.txt</td>\n",
       "      <td>Hombre de 57 años. No alergias medicamentosas ...</td>\n",
       "      <td>[**Hombre**] de [**57 años**]. No alergias med...</td>\n",
       "      <td>[**Hombre**] de [**57 años**]. No alergias med...</td>\n",
       "      <td>[**Hombre**] de [**57 años**]. No alergias med...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            txtname  \\\n",
       "0                 CARMEN-I_CC_2.txt   \n",
       "1                 CARMEN-I_CC_3.txt   \n",
       "2                 CARMEN-I_CC_4.txt   \n",
       "3                 CARMEN-I_CC_5.txt   \n",
       "4    CARMEN-I_IA_ANTECEDENTES_1.txt   \n",
       "..                              ...   \n",
       "95  CARMEN-I_IA_ANTECEDENTES_57.txt   \n",
       "96  CARMEN-I_IA_ANTECEDENTES_58.txt   \n",
       "97  CARMEN-I_IA_ANTECEDENTES_59.txt   \n",
       "98   CARMEN-I_IA_ANTECEDENTES_6.txt   \n",
       "99  CARMEN-I_IA_ANTECEDENTES_60.txt   \n",
       "\n",
       "                                             Replaced  \\\n",
       "0   Realizo llamada telefónica. Refiere buen desca...   \n",
       "1   Visita unidad del dolor. Ver informe de evoluc...   \n",
       "2   Primera llamada HDOM COVID-19 POSITIVO\\n.\\nTra...   \n",
       "3   Primera llamada HDOM COVID-19 POSITIVO\\nTrabaj...   \n",
       "4   Varón de 79 años, sin alergias a medicamentos ...   \n",
       "..                                                ...   \n",
       "95  Antecedentes personales:\\nNatural de Islas Fal...   \n",
       "96  Hombre de 63 años de edad, sin alergias medica...   \n",
       "97  Vive en residencia, cognitivamente preservada,...   \n",
       "98  Varón de 61 años, sin alergias medicamentosas ...   \n",
       "99  Hombre de 57 años. No alergias medicamentosas ...   \n",
       "\n",
       "                                               Masked  \\\n",
       "0   Realizo llamada telefónica. Refiere buen desca...   \n",
       "1   Visita unidad del dolor. Ver informe de evoluc...   \n",
       "2   Primera llamada HDOM COVID-19 POSITIVO\\n.\\nTra...   \n",
       "3   Primera llamada HDOM COVID-19 POSITIVO\\nTrabaj...   \n",
       "4   [**Varón**] de [**79 años**], sin alergias a m...   \n",
       "..                                                ...   \n",
       "95  Antecedentes personales:\\nNatural de [**Islas ...   \n",
       "96  [**Hombre**] de [**63 años**] de edad, sin ale...   \n",
       "97  Vive en residencia, cognitivamente preservada,...   \n",
       "98  [**Varón**] de [**61 años**], sin alergias med...   \n",
       "99  [**Hombre**] de [**57 años**]. No alergias med...   \n",
       "\n",
       "                                           Prediction  \\\n",
       "0   Realizo llamada telefónica. Refiere buen desca...   \n",
       "1   Visita unidad del dolor. Ver informe de evoluc...   \n",
       "2   Primera llamada HDOM COVID-19 POSITIVO.\\nTraba...   \n",
       "3   Primera llamada HDOM COVID-19 POSITIVO\\nTrabaj...   \n",
       "4   [**Varón**] de [**79 años**], sin alergias a m...   \n",
       "..                                                ...   \n",
       "95  Antecedentes personales:\\nNatural de [**Islas ...   \n",
       "96  [**Hombre**] de [**63 años**] de edad, sin ale...   \n",
       "97  Vive en residencia, cognitivamente preservada,...   \n",
       "98  [**Varón**] de [**61 años**], sin alergias med...   \n",
       "99  [**Hombre**] de [**57 años**]. No alergias med...   \n",
       "\n",
       "                                 Prediction_processed  precision    recall  \\\n",
       "0   Realizo llamada telefónica. Refiere buen desca...   0.689655  1.000000   \n",
       "1   Visita unidad del dolor. Ver informe de evoluc...   0.166667  0.666667   \n",
       "2   Primera llamada HDOM COVID-19 POSITIVO\\n.\\nTra...   0.947368  0.947368   \n",
       "3   Primera llamada HDOM COVID-19 POSITIVO\\nTrabaj...   0.827950  0.956522   \n",
       "4   [**Varón**] de [**79 años**], sin alergias a m...   0.882353  0.937500   \n",
       "..                                                ...        ...       ...   \n",
       "95  Antecedentes personales:\\nNatural de [**Islas ...   0.466667  1.000000   \n",
       "96  [**Hombre**] de [**63 años**] de edad, sin ale...   0.750000  0.916667   \n",
       "97  Vive en residencia, cognitivamente preservada,...   0.500000  1.000000   \n",
       "98  [**Varón**] de [**61 años**], sin alergias med...   0.894444  0.923077   \n",
       "99  [**Hombre**] de [**57 años**]. No alergias med...   1.000000  0.925000   \n",
       "\n",
       "          f1  masked_count       cos  lev  \n",
       "0   0.816327            20  0.999295   54  \n",
       "1   0.266667             3  1.000000   66  \n",
       "2   0.947368            19  1.000000   12  \n",
       "3   0.887604            23  1.000000   60  \n",
       "4   0.909091            16  1.000000   18  \n",
       "..       ...           ...       ...  ...  \n",
       "95  0.636364             7  1.000000   48  \n",
       "96  0.825000            12  1.000000   30  \n",
       "97  0.666667             1  1.000000    6  \n",
       "98  0.908535            13  0.995160    0  \n",
       "99  0.961039            20  1.000000    0  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ed41e",
   "metadata": {},
   "source": [
    "# Viewing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "903f5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5c1fc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTECEDENTES:\n",
      "- No alergias conocidas\n",
      "- No hábitos tóxicos.\n",
      "- Hipertensión arterial en tratamiento.\n",
      "- Tuberculosis pulmonar en la infancia.\n",
      "- Herida por arma de fuego en tórax en la juventud.\n",
      "- Neumonía en lóbulo inferior derecho en 2021\n",
      "- Síndrome depresivo.\n",
      "- Neumonitis por hipersensibilidad fibrótica, seguimiento en consultas: No se descarta una EAS asociada aunque baja probabilidad (RNAPIII sin clínica). En comité se decide inicio de prednisona con TCARde control con progresión con mayor aspecto de NINE por lo que se iniciómicofenolato.\n",
      "- Osteoporosis.\n",
      "*Pendiente de realizar ecografía abdominal para descartar litiasis.\n",
      "TRATAMIENTO HABITUAL: PDN 5, MPA 720/12, Mastical D, omeprazol, tiotropio,lisinopil,alprazolam,formoterol/budesonida,paroxetina,lormetaz epam, paracetamol, colecalciferol\n",
      "FILIACIÓN :\n",
      "Natural de Níger, ha vivido en Curazao, Georgia, Islas Feroe, Luxemburgo.Vacunada con dos dosis para SARS-COv-2\n",
      "No deterioro cognitivo, vive con su sobrino, sale a la calle pero pocos metros, hace pequeñas tareas del hogar.\n"
     ]
    }
   ],
   "source": [
    "print(df2['Replaced'][a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efcfef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTECEDENTES:\n",
      "- No alergias conocidas\n",
      "- No hábitos tóxicos.\n",
      "- Hipertensión arterial en tratamiento.\n",
      "- Tuberculosis pulmonar en la infancia.\n",
      "- Herida por arma de fuego en tórax en la juventud.\n",
      "- Neumonía en lóbulo inferior derecho en [**2021**]\n",
      "- Síndrome depresivo.\n",
      "- Neumonitis por hipersensibilidad fibrótica, seguimiento en consultas: No se descarta una EAS asociada aunque baja probabilidad (RNAPIII sin clínica). En comité se decide inicio de prednisona con TCARde control con progresión con mayor aspecto de NINE por lo que se iniciómicofenolato.\n",
      "- Osteoporosis.\n",
      "*Pendiente de realizar ecografía abdominal para descartar litiasis.\n",
      "TRATAMIENTO HABITUAL: PDN 5, MPA 720/12, Mastical D, omeprazol, tiotropio,lisinopil,alprazolam,formoterol/budesonida,paroxetina,lormetaz epam, paracetamol, colecalciferol\n",
      "FILIACIÓN :\n",
      "Natural de [**Níger**], ha vivido en [**Curazao**], [**Georgia**], [**Islas Feroe**], [**Luxemburgo**].Vacunada con dos dosis para SARS-COv-2\n",
      "No deterioro cognitivo, vive con su [**sobrino**], sale a la calle pero pocos metros, hace pequeñas tareas del hogar.\n"
     ]
    }
   ],
   "source": [
    "print(df2['Masked'][a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49c752ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTECEDENTES:\n",
      "- No alergias conocidas\n",
      "- No hábitos tóxicos.\n",
      "- Hipertensión arterial en tratamiento.\n",
      "- Tuberculosis pulmonar en la infancia.\n",
      "- Herida por arma de fuego en tórax en la juventud.\n",
      "- Neumonía en lóbulo inferior derecho en [**2021**]\n",
      "- Síndrome depresivo.\n",
      "- Neumonitis por hipersensibilidad fibrótica, seguimiento en consultas: No se descarta una EAS asociada aunque baja probabilidad (RNAPIII sin clínica). En comité se decide inicio de prednisona con TCARde control con progresión con mayor aspecto de NINE por lo que se iniciómicofenolato.\n",
      "- Osteoporosis.\n",
      "*Pendiente de realizar ecografía abdominal para descartar litiasis.\n",
      "TRATAMIENTO HABITUAL: PDN 5, MPA 720/12, Mastical D, omeprazol, tiotropio,lisinopil,alprazolam,formoterol/budesonida,paroxetina,lormetaz epam, paracetamol, colecalciferol\n",
      "FILIACIÓN :\n",
      "Natural de [**Níger**], ha vivido en [**Curazao**], [**Georgia**], [**Islas Feroe**], [**Luxemburgo**].Vacunada con dos dosis para SARS-COv-2\n",
      "No deterioro cognitivo, vive con su [**sobrino**], sale a la calle pero pocos metros, hace pequeñas tareas del hogar.\n"
     ]
    }
   ],
   "source": [
    "print(df2['Prediction'][a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90898f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTECEDENTES:\n",
      "- No alergias conocidas\n",
      "- No hábitos tóxicos.\n",
      "- Hipertensión arterial en tratamiento.\n",
      "- Tuberculosis pulmonar en la infancia.\n",
      "- Herida por arma de fuego en tórax en la juventud.\n",
      "- Neumonía en lóbulo inferior derecho en [**2021**]\n",
      "- Síndrome depresivo.\n",
      "- Neumonitis por hipersensibilidad fibrótica, seguimiento en consultas: No se descarta una EAS asociada aunque baja probabilidad (RNAPIII sin clínica). En comité se decide inicio de prednisona con TCARde control con progresión con mayor aspecto de NINE por lo que se iniciómicofenolato.\n",
      "- Osteoporosis.\n",
      "*Pendiente de realizar ecografía abdominal para descartar litiasis.\n",
      "TRATAMIENTO HABITUAL: PDN 5, MPA 720/12, Mastical D, omeprazol, tiotropio,lisinopil,alprazolam,formoterol/budesonida,paroxetina,lormetaz epam, paracetamol, colecalciferol\n",
      "FILIACIÓN :\n",
      "Natural de [**Níger**], ha vivido en [**Curazao**], [**Georgia**], [**Islas Feroe**], [**Luxemburgo**].Vacunada con dos dosis para SARS-COv-2\n",
      "No deterioro cognitivo, vive con su [**sobrino**], sale a la calle pero pocos metros, hace pequeñas tareas del hogar.\n"
     ]
    }
   ],
   "source": [
    "print(df2['Prediction_processed'][a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cb1abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked=df2['Masked'][a]\n",
    "generated=df2['Prediction_processed'][a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d32221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2021\n",
      "1.0 Níger\n",
      "1.0 Curazao\n",
      "1.0 Georgia\n",
      "1.0 Islas Feroe\n",
      "1.0 Luxemburgo\n",
      "1.0 sobrino\n"
     ]
    }
   ],
   "source": [
    "masked=masked.replace('\\n','')\n",
    "generated=generated.replace('\\n','')\n",
    "\n",
    "ground_truth_matches = re.finditer(r'\\[\\*\\*(.*?)\\*\\*\\]', masked)\n",
    "ground_truth_positions = {}\n",
    "cnt=0\n",
    "for match in ground_truth_matches:\n",
    "    start = match.start(1)-(cnt*2+1)*3  # start of the group (excluding [**)\n",
    "    end = match.end(1)-(cnt*2+1)*3\n",
    "    cnt+=1# end of the group (excluding **])\n",
    "    ground_truth_positions[(start, end)] = replace_special_characters(match.group(1))\n",
    "\n",
    "predictions_matches = re.finditer(r'\\[\\*\\*(.*?)\\*\\*\\]', generated)\n",
    "predictions_positions = {}\n",
    "cnt=0\n",
    "for match in predictions_matches:\n",
    "    start = match.start(1)-(cnt*2+1)*3  # start of the group (excluding [**)\n",
    "    end = match.end(1)-(cnt*2+1)*3\n",
    "    cnt+=1# end of the group (excluding **])\n",
    "    predictions_positions[(start, end)] = replace_special_characters(match.group(1))\n",
    "\n",
    "totalwordcnt_ground_truth = len(ground_truth_positions)\n",
    "score_total=0\n",
    "for pos_g in ground_truth_positions:\n",
    "    for pos_p in predictions_positions:\n",
    "        if (pos_p[0]<=pos_g[0] and pos_p[1]>=pos_g[1]) or (pos_p[0]>=pos_g[0] and pos_p[1]<=pos_g[1]):\n",
    "            score_temp = partial_score(ground_truth_positions[pos_g],predictions_positions[pos_p])\n",
    "            score_total += score_temp\n",
    "            print(score_temp,ground_truth_positions[pos_g])\n",
    "\n",
    "score_total = score_total/totalwordcnt_ground_truth\n",
    "recall = score_total\n",
    "\n",
    "totalwordcnt_predictions = len(predictions_positions)\n",
    "score_total=0\n",
    "for pos_p in predictions_positions:\n",
    "    for pos_g in ground_truth_positions:\n",
    "        if (pos_g[0]<=pos_p[0] and pos_g[1]>=pos_p[1]) or (pos_g[0]>=pos_p[0] and pos_g[1]<=pos_p[1]):\n",
    "            score_temp = partial_score(predictions_positions[pos_p],ground_truth_positions[pos_g])\n",
    "            score_total += score_temp\n",
    "\n",
    "score_total = score_total/totalwordcnt_predictions\n",
    "precision = score_total\n",
    "\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8301ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f4d4eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c85b9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(227, 231): '2021',\n",
       " (812, 817): 'Níger',\n",
       " (832, 839): 'Curazao',\n",
       " (841, 848): 'Georgia',\n",
       " (850, 861): 'Islas Feroe',\n",
       " (863, 873): 'Luxemburgo',\n",
       " (948, 955): 'sobrino'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c046fb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(227, 231): '2021',\n",
       " (812, 817): 'Níger',\n",
       " (832, 839): 'Curazao',\n",
       " (841, 848): 'Georgia',\n",
       " (850, 861): 'Islas Feroe',\n",
       " (863, 873): 'Luxemburgo',\n",
       " (948, 955): 'sobrino'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd817d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx4090",
   "language": "python",
   "name": "rtx4090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
