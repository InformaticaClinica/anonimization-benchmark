{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.context.llm_context import LLMContext\n",
    "from llm.strategy.big_llama_model import BigLlamaModel\n",
    "from llm.strategy.big_llama3_1_model import BigLlama3_1Model\n",
    "from llm.strategy.small_llama_model import SmallLlamaModel\n",
    "from llm.strategy.big_mistral_model import BigMistralModel\n",
    "from llm.strategy.haiku3_model import Haiku3Model\n",
    "from llm.strategy.sonet3_model import Sonet3Model\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data/processed/txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(name):\n",
    "    try:\n",
    "        os.mkdir(name)\n",
    "        print(f\"Folder '{name}' created successfully\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating the folder '{name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(filename, text):\n",
    "    with open(filename, 'w') as archivo:\n",
    "        archivo.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_and_masked_carmen(name):\n",
    "    filename = f'./data/processed/txt/{name}'\n",
    "    filename_result = f'./data/processed/masked/{name}'\n",
    "    with open(filename, 'r') as archivo:\n",
    "        text = archivo.read()\n",
    "\n",
    "    with open(filename_result, 'r') as archivo:\n",
    "        text_masked = archivo.read()\n",
    "\n",
    "    return [text, text_masked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_metrics(metrics_data, precision, recall, f1, cosine_sim, levenshtein_distance, labels):\n",
    "    metrics_data[\"precision\"] = precision\n",
    "    metrics_data[\"recall\"] = recall\n",
    "    metrics_data[\"f1\"] = f1\n",
    "    metrics_data[\"cos\"] = cosine_sim\n",
    "    metrics_data[\"levenshtein\"] = levenshtein_distance\n",
    "    metrics_data[\"ground_truth\"] = labels[0]\n",
    "    metrics_data[\"generated\"] = labels[1]\n",
    "    if int(metrics_data[\"levenshtein\"]) == 0:\n",
    "        metrics_data[\"inv_levenshtein\"] = 1\n",
    "    else: \n",
    "        metrics_data[\"inv_levenshtein\"] = (1/metrics_data[\"levenshtein\"])\n",
    "        metrics_data[\"overall\"] = metrics_data[\"precision\"] + metrics_data[\"recall\"] +  metrics_data[\"f1\"] + metrics_data[\"cos\"] + metrics_data[\"inv_levenshtein\"]\n",
    "    return metrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(name_model, list_data):\n",
    "    list_data = pd.DataFrame(list_data)\n",
    "    list_data.to_csv(f'data/metrics/{name_model}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"\\[W008\\] Evaluating Doc.similarity based on empty vectors\")\n",
    "nlp = spacy.load(\"es_core_news_md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_similarity(str1, str2, threshold=0.8):\n",
    "    doc1 = nlp(str1)\n",
    "    doc2 = nlp(str2)\n",
    "    similarity = doc1.similarity(doc2)\n",
    "    return similarity >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_adverbios_preposiciones_determinantes(texto):\n",
    "    doc = nlp(texto)\n",
    "    # Eliminar preposiciones (ADP) y determinantes (DET)\n",
    "    tokens_filtrados = [token.text for token in doc if token.pos_ not in ('ADP', 'DET')]\n",
    "    return ' '.join(tokens_filtrados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2, show_progress=True):\n",
    "    \"\"\"\n",
    "    Calcula la distancia de Levenshtein entre dos cadenas.\n",
    "\n",
    "    La distancia de Levenshtein es el número mínimo de operaciones de edición \n",
    "    (inserción, eliminación o sustitución de un carácter) necesarias para \n",
    "    transformar una cadena en otra.\n",
    "\n",
    "    Parámetros:\n",
    "        s1 (str): Primera cadena\n",
    "        s2 (str): Segunda cadena\n",
    "        show_progress (bool): Si es True, muestra una barra de progreso. \n",
    "                              Por defecto es False.\n",
    "    Retorna:\n",
    "        int: La distancia de Levenshtein entre s1 y s2\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Usar tqdm solo si show_progress es True\n",
    "    iterable = tqdm(s1) if show_progress else s1\n",
    "\n",
    "    if len(s1) < len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = list(range(len(s2) + 1))\n",
    "    for i, c1 in enumerate(iterable):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(text_hoped, text_generated):\n",
    "    vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w[\\w\\-/]*\\b\")\n",
    "    tfidf_matrix = vectorizer.fit_transform([text_hoped, text_generated])\n",
    "\n",
    "    try:\n",
    "        cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    except: \n",
    "        return 0.0\n",
    "    return cosine_sim[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(ground_truth, predictions):\n",
    "    # Convertir arrays de ground_truth y predictions a listas de str\n",
    "    ground_truth_processed = np.array([eliminar_adverbios_preposiciones_determinantes(str(item)) for item in ground_truth])\n",
    "    predictions_processed = np.array([eliminar_adverbios_preposiciones_determinantes(str(item)) for item in predictions])\n",
    "\n",
    "    # Crear matrices de similitud de coseno y embedding \n",
    "    get_cos_sim_vectorized = np.vectorize(lambda gt, pred: get_cos_sim(str(gt), str(pred)))\n",
    "    embedding_similarity_vectorized = np.vectorize(lambda gt, pred: embedding_similarity(str(gt), str(pred)))\n",
    "\n",
    "    cosine_results = get_cos_sim_vectorized(ground_truth_processed[:, None], predictions_processed[None, :])\n",
    "    embedding_results = embedding_similarity_vectorized(ground_truth_processed[:, None], predictions_processed[None, :])\n",
    "    \n",
    "    # Promediar las similitudes\n",
    "    avg_similarities = (cosine_results + embedding_results) / 2\n",
    "\n",
    "    # Determinar verdaderos positivos\n",
    "    matches = avg_similarities > 0.5\n",
    "    true_positives = np.sum(np.any(matches, axis=1))\n",
    "\n",
    "    # Determinar falsos negativos\n",
    "    false_negatives = len(ground_truth) - true_positives\n",
    "\n",
    "    # Determinar falsos positivos\n",
    "    predicted_matches = np.any(matches, axis=0)\n",
    "    false_positives = len(predictions) - np.sum(predicted_matches)\n",
    "\n",
    "    # Cálculo de métricas\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f1)\n",
    "\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(masked, generated):\n",
    "    \"\"\" \n",
    "    Input: \n",
    "        - masked (str): Ground_truth text\n",
    "        - generated(str): Text to be evaluated\n",
    "\n",
    "    Output:\n",
    "        - Precision, Recall and F1 (float)\n",
    "    \"\"\"\n",
    "    ground_truth = re.findall(r'\\[\\*\\*(.*?)\\*\\*\\]', masked)\n",
    "    predictions = re.findall(r'\\[\\*\\*(.*?)\\*\\*\\]', generated)\n",
    "    labels = [ground_truth, predictions]\n",
    "    return [calc_metrics(ground_truth, predictions), labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(text_hoped, text_generated):\n",
    "    [cal_met, labels] = evaluate(text_hoped, text_generated)\n",
    "    cosine_sim = get_cos_sim(text_hoped, text_generated)\n",
    "    text_generated = text_generated.replace('[**', '').replace('**]', '')\n",
    "    text_hoped = text_hoped.replace('[**', '').replace('**]', '')\n",
    "    result = levenshtein_distance(text_generated, text_hoped[:len(text_generated)], show_progress=False)\n",
    "    return cosine_sim, cal_met, result, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_score(X, Y):\n",
    "    if X in Y or Y in X:\n",
    "        x_words = X.split()\n",
    "        y_words = Y.split()\n",
    "\n",
    "        counter_a1 = Counter(x_words)\n",
    "        counter_a2 = Counter(y_words)\n",
    "\n",
    "        matches = 0\n",
    "\n",
    "        for element in counter_a1:\n",
    "            if element in counter_a2:\n",
    "\n",
    "                matches += min(counter_a1[element], counter_a2[element])\n",
    "\n",
    "        return matches / len(x_words) if len(x_words) > 0 else 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def replace_special_characters(text):\n",
    "    # Define the pattern to match special characters including . / and -\n",
    "    pattern = r'[!@#$%^&*()_+={}\\[\\]:;\"\\'<>,?\\\\|`~./-]'\n",
    "    \n",
    "    # Replace the matched characters with a space\n",
    "    result = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def evaluate2(masked,generated):\n",
    "    masked=masked.replace('\\n','')\n",
    "    generated=generated.replace('\\n','')\n",
    "\n",
    "    ground_truth_matches = re.finditer(r'\\[\\*\\*(.*?)\\*\\*\\]', masked)\n",
    "    ground_truth_positions = {}\n",
    "    cnt=0\n",
    "    for match in ground_truth_matches:\n",
    "        start = match.start(1)-(cnt*2+1)*3  # start of the group (excluding [**)\n",
    "        end = match.end(1)-(cnt*2+1)*3\n",
    "        cnt+=1# end of the group (excluding **])\n",
    "        ground_truth_positions[(start, end)] = replace_special_characters(match.group(1))\n",
    "\n",
    "    predictions_matches = re.finditer(r'\\[\\*\\*(.*?)\\*\\*\\]', generated)\n",
    "    predictions_positions = {}\n",
    "    cnt=0\n",
    "    for match in predictions_matches:\n",
    "        start = match.start(1)-(cnt*2+1)*3  # start of the group (excluding [**)\n",
    "        end = match.end(1)-(cnt*2+1)*3\n",
    "        cnt+=1# end of the group (excluding **])\n",
    "        predictions_positions[(start, end)] = replace_special_characters(match.group(1))\n",
    "\n",
    "    totalwordcnt_ground_truth = len(ground_truth_positions)\n",
    "    score_total=0\n",
    "    for pos_g in ground_truth_positions:\n",
    "        for pos_p in predictions_positions:\n",
    "            if (pos_p[0]<=pos_g[0] and pos_p[1]>=pos_g[1]) or (pos_p[0]>=pos_g[0] and pos_p[1]<=pos_g[1]):\n",
    "                score_temp = partial_score(ground_truth_positions[pos_g],predictions_positions[pos_p])\n",
    "                score_total += score_temp\n",
    "\n",
    "    score_total = score_total/totalwordcnt_ground_truth\n",
    "    recall = score_total\n",
    "\n",
    "    totalwordcnt_predictions = len(predictions_positions)\n",
    "    score_total=0\n",
    "    for pos_p in predictions_positions:\n",
    "        for pos_g in ground_truth_positions:\n",
    "            if (pos_g[0]<=pos_p[0] and pos_g[1]>=pos_p[1]) or (pos_g[0]>=pos_p[0] and pos_g[1]<=pos_p[1]):\n",
    "                score_temp = partial_score(predictions_positions[pos_p],ground_truth_positions[pos_g])\n",
    "                score_total += score_temp\n",
    "\n",
    "    score_total = score_total/totalwordcnt_predictions\n",
    "    precision = score_total\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo:\n",
      "Errores de clasificacion: {'hilandero': ('PROFESION', 'NUMERO_TELEFONO'), '983425634': ('NUMERO_TELEFONO', 'PROFESION')}\n",
      "Claves no enconctradas en el segundo diccionario: ['15/09']\n"
     ]
    }
   ],
   "source": [
    "def compute_classification_agreement(dict1, dict2):\n",
    "    # Look for key disagreement\n",
    "    keys_not_present_in_dict2 = list(set(dict1.keys()) - set(dict2.keys()))\n",
    "    \n",
    "    # look for misclassifications\n",
    "    disagreement_in_values = {}\n",
    "    for key in dict1.keys() & dict2.keys():\n",
    "        if dict1[key] != dict2[key]:\n",
    "            disagreement_in_values[key] = (dict1[key], dict2[key])\n",
    "\n",
    "    return disagreement_in_values, keys_not_present_in_dict2\n",
    "\n",
    "\n",
    "\n",
    "# Modificacion del un label_dict para usar como ejmeplo\n",
    "import pandas as pd \n",
    "import random \n",
    "filename = r'data\\processed\\ann\\CARMEN-I_CC_1.csv'\n",
    "\n",
    "# Transform .ann file to dictionary\n",
    "label_dict = pd.read_csv(filename, header=None)[[0,3]].set_index(3).to_dict()[0]\n",
    "dict_modificado = label_dict.copy()\n",
    "\n",
    "# Eliminar una clave al azar\n",
    "key_to_remove = random.choice(list(dict_modificado.keys()))\n",
    "del dict_modificado[key_to_remove]\n",
    "\n",
    "# Seleccionar 3 claves al azar para intercambiar sus valores\n",
    "keys_to_swap = random.sample(list(dict_modificado.keys()), 3)\n",
    "val1, val2, val3 = dict_modificado[keys_to_swap[0]], dict_modificado[keys_to_swap[1]], dict_modificado[keys_to_swap[2]]\n",
    "\n",
    "# Intercambiar valores entre las tres claves\n",
    "dict_modificado[keys_to_swap[0]] = val2\n",
    "dict_modificado[keys_to_swap[1]] = val3\n",
    "dict_modificado[keys_to_swap[2]] = val1\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "print('Ejemplo:')\n",
    "diferencias, unicas_dict1 = comparar_diccionarios(label_dict, dict_modificado)\n",
    "print(\"Errores de clasificacion:\", diferencias)\n",
    "print(\"Claves no enconctradas en el segundo diccionario:\", unicas_dict1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonimized(llm=None, name_model=\"\", data=None):\n",
    "    counter = 0\n",
    "    context = LLMContext(llm)\n",
    "    list_data  = []\n",
    "    for filename in sorted(os.listdir(PATH)):\n",
    "        print(filename)\n",
    "        metrics_data = {}\n",
    "        metrics_data[\"filename\"] = filename\n",
    "        try:\n",
    "            [text, text_hoped] = get_text_and_masked_carmen(filename)\n",
    "            data[\"user\"] = text\n",
    "            text_generated = context.generate_response(data)\n",
    "            create_folder(f'data/anon/raw/{name_model}')\n",
    "            save_file(f'data/anon/raw/{name_model}/{filename}', text_generated)\n",
    "            cosine_sim, cal_met, result, labels = calculate_metrics(text_hoped, text_generated)\n",
    "            metrics_data = store_metrics(metrics_data, cal_met[0],cal_met[1], cal_met[2], cosine_sim, result, labels)\n",
    "            list_data.append(metrics_data)\n",
    "            counter += 1\n",
    "            if counter >= 100:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(e) \n",
    "            metrics_data[\"fail\"] = 1\n",
    "        finally:\n",
    "            list_data.append(metrics_data)\n",
    "    save_metrics(name_model, list_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data[\"system\"] = \"\"\"\n",
    "You are an anonymization tool in identifying attributes in texts that can identify or quasi-identify a user.\n",
    "Return only the original text with the identification and labeling of the patient's personal information by adding it between [** and **].\n",
    "Following are attributes that you must anonymize.\n",
    "\n",
    "- Names\n",
    "Example:\n",
    "En seguimiento por Hematología Centro Médico Aspasia (Dra. Valvanera).   ->\n",
    "En seguimiento por Hematología [**Centro Médico Aspasia**] (Dra. [**Valvanera**]).\n",
    "\n",
    "- Ages\n",
    "Example: \n",
    "Varón de 41 años.   ->\n",
    "[**Varón**] de [**41 años**].\n",
    "\n",
    "- Sexes\n",
    "Example: \n",
    "Varón de 41 años.   ->\n",
    "[**Varón**] de [**41 años**].\n",
    "\n",
    "- Professions\n",
    "Example: \n",
    "Trabaja como profesor.   ->\n",
    "Trabaja como [**profesor**].\n",
    "\n",
    "- Relatives\n",
    "Example: \n",
    "Vive con suegro y 2 yernos.   ->\n",
    "Vive con [**suegro**] y [**2 yernos**].\n",
    "\n",
    "- Dates\n",
    "Example: \n",
    "ha estado viviendo en el Centro desde septiembre de 2008.   ->\n",
    "ha estado viviendo en el [**Centro**] desde [**septiembre de 2008**].\n",
    "\n",
    "- Phone numbers\n",
    "Example: \n",
    "contactando con el siguiente número de teléfono +50 88 078 68 49.   ->\n",
    "contactando con el siguiente número de teléfono [**+50 88 078 68 49**].\n",
    "\n",
    "- Identification numbers\n",
    "Example:\n",
    "El paciente otorga su consentimiento informado para participar en el estudio del protocolo WYX/8408/5545.   ->\n",
    "El paciente otorga su consentimiento informado para participar en el estudio del protocolo [**WYX/8408/5545.**]\n",
    "\n",
    "- Institutions, hospitals, health centers, etc\n",
    "Example: \n",
    "En seguimiento por Hematología Centro Médico Aspasia (Dra. Valvanera).   ->\n",
    "En seguimiento por Hematología [**Centro Médico Aspasia**] (Dra. [**Valvanera**]).\n",
    "Example:\n",
    "Control en Centro Salud Mental Reyes Católicos.   ->\n",
    "Control en [**Centro Salud Mental Reyes Católicos**].\n",
    "\n",
    "- Countries, territories, streets, etc\n",
    "Example:\n",
    "nacido en la República Italiana.   ->\n",
    "nacido en la [**República Italiana**].\n",
    "Example:\n",
    "ha estado viviendo en el Centro desde septiembre de 2008.   ->\n",
    "ha estado viviendo en el [**Centro**] desde [**septiembre de 2008**].\n",
    "Example:\n",
    "la dirección es Calle de Victor Hugo 39.   ->\n",
    "la dirección es [**Calle de Victor Hugo 39**].\n",
    "\n",
    "- Website URLs\n",
    "participar a través del siguiente enlace: https://www.donarsang.gencat.cat/covid19.   ->\n",
    "participar a través del siguiente enlace: [**https://www.donarsang.gencat.cat/covid19**].\n",
    "\n",
    "- Drugs -\n",
    "Does not include drugs on anonymization\n",
    "Example: \n",
    "Omeprazol 20 mg/24h, fluticasona 50mcg/salmeterol 500mcg/12h -> \n",
    "Omeprazol 20 mg/24h, fluticasona 50mcg/salmeterol 500mcg/12h\n",
    "\n",
    "\n",
    "- Other sensitive information such as races, ethnicities, sexual orientation, dietary preferences, etc\n",
    "Example:\n",
    "raça blanca   ->\n",
    "[**raça blanca**]\n",
    "Example:\n",
    "Hsh\n",
    "[**Hsh**]\n",
    "Example:\n",
    "Vegetarià\n",
    "[**Vegetarià**]\n",
    "\n",
    "\n",
    "Do not comment anything else.\n",
    "Besides the anonymized attributes, provide the rest of the text exactly the same, including special characters and \\n symbols.\n",
    "Do not correct any typos or spacing errors at your discretion.\n",
    "For example, if the time is written as 31/12/2000-0 9:20:00 with incorrect spacing, do not return it corrected as 31/12/2000-09:20:00.\n",
    "Also, for example, if FLUTICASONA + AZELA STINA4 is written with incorrect spacing, do not return it corrected as FLUTICASONA + AZELASTINA 4.\n",
    "Only focus on the anonymization tasks I have specified, and ignore any typos or spacing errors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3262"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"system\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonimized(llm=Sonet3Model(), name_model=\"sonet3\", data=data)\n",
    "# anonimized(llm=Haiku3Model(), name_model=\"haiku3\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 12)\n",
      "0.5149565578551344\n",
      "0.8662432096923663\n",
      "0.6051813033233288\n",
      "0.9926035614686615\n",
      "5.22\n",
      "0.499389044384734\n",
      "3.334622858268047\n"
     ]
    }
   ],
   "source": [
    "haiku3_data = pd.read_csv('./data/metrics/haiku3.csv')\n",
    "haiku3_data = haiku3_data[haiku3_data['fail'] != 0]\n",
    "print(haiku3_data.shape)\n",
    "print(haiku3_data[\"precision\"].mean())\n",
    "print(haiku3_data[\"recall\"].mean())\n",
    "print(haiku3_data[\"f1\"].mean())\n",
    "print(haiku3_data[\"cos\"].mean())\n",
    "print(haiku3_data['levenshtein'].mean())\n",
    "print(haiku3_data['inv_levenshtein'].mean())\n",
    "print(haiku3_data['overall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.771130685141101\n",
      "0.8637395815367964\n",
      "0.7971793813441076\n",
      "0.9980584983988646\n",
      "4.72\n",
      "0.5568777451450805\n",
      "3.8291187711441372\n"
     ]
    }
   ],
   "source": [
    "sonet3_data = pd.read_csv('./data/metrics/sonet3.csv')\n",
    "sonet3_data = sonet3_data[sonet3_data['fail'] != 0]\n",
    "print(sonet3_data[\"precision\"].mean())\n",
    "print(sonet3_data[\"recall\"].mean())\n",
    "print(sonet3_data[\"f1\"].mean())\n",
    "print(sonet3_data[\"cos\"].mean())\n",
    "print(sonet3_data['levenshtein'].mean())\n",
    "print(sonet3_data['inv_levenshtein'].mean())\n",
    "print(sonet3_data['overall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonimized(llm=BigLlamaModel(), name_model=\"big_llama3\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 11)\n",
      "0.6813861500207861\n",
      "0.862360347729612\n",
      "0.7293225022963162\n",
      "0.9968518990471088\n",
      "8.55\n",
      "0.5018324559038845\n",
      "3.7717533549977076\n"
     ]
    }
   ],
   "source": [
    "big_llama_data = pd.read_csv('./data/metrics/big_llama3.csv')\n",
    "print(big_llama_data.shape)\n",
    "print(big_llama_data[\"precision\"].mean())\n",
    "print(big_llama_data[\"recall\"].mean())\n",
    "print(big_llama_data[\"f1\"].mean())\n",
    "print(big_llama_data[\"cos\"].mean())\n",
    "print(big_llama_data['levenshtein'].mean())\n",
    "print(big_llama_data['inv_levenshtein'].mean())\n",
    "print(big_llama_data['overall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonimized(llm=SmallLlamaModel(), name_model=\"small_llama3\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 12)\n",
      "0.35647973459698223\n",
      "0.5780418546535994\n",
      "0.39271663554292874\n",
      "0.9910574538871632\n",
      "24.41\n",
      "0.37034628812668274\n",
      "2.6886419668073565\n"
     ]
    }
   ],
   "source": [
    "small_llama = pd.read_csv('./data/metrics/small_llama3.csv')\n",
    "small_llama = small_llama[small_llama['fail'] != 0]\n",
    "print(small_llama.shape)\n",
    "print(small_llama[\"precision\"].mean())\n",
    "print(small_llama[\"recall\"].mean())\n",
    "print(small_llama[\"f1\"].mean())\n",
    "print(small_llama[\"cos\"].mean())\n",
    "print(small_llama['levenshtein'].mean())\n",
    "print(small_llama['inv_levenshtein'].mean())\n",
    "print(small_llama['overall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonimized(llm=BigMistralModel(), name_model=\"big_mistral\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 12)\n",
      "0.6047592555707106\n",
      "0.4756985196536956\n",
      "0.4682127617200233\n",
      "0.9796671029865229\n",
      "24.51\n",
      "0.5461363453517354\n",
      "3.074473985282688\n"
     ]
    }
   ],
   "source": [
    "mistral = pd.read_csv('./data/metrics/big_mistral.csv')\n",
    "print(mistral.shape)\n",
    "print(mistral[\"precision\"].mean())\n",
    "print(mistral[\"recall\"].mean())\n",
    "print(mistral[\"f1\"].mean())\n",
    "print(mistral[\"cos\"].mean())\n",
    "print(mistral['levenshtein'].mean())\n",
    "print(mistral['inv_levenshtein'].mean())\n",
    "print(mistral['overall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anonimized(llm=BigLlama3_1Model(), name_model=\"BigLlama3_1Model\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 12)\n",
      "0.8972680765675449\n",
      "0.9445218074838819\n",
      "0.9141201245585546\n",
      "0.9983652007630383\n",
      "1.7\n",
      "0.8459583333333334\n",
      "4.600233542706353\n"
     ]
    }
   ],
   "source": [
    "BigLlama3_1Model = pd.read_csv('./data/metrics/BigLlama3_1Model.csv')\n",
    "BigLlama3_1Model = BigLlama3_1Model[BigLlama3_1Model['fail'] != 0]\n",
    "print(BigLlama3_1Model.shape)\n",
    "print(BigLlama3_1Model[\"precision\"].mean())\n",
    "print(BigLlama3_1Model[\"recall\"].mean())\n",
    "print(BigLlama3_1Model[\"f1\"].mean())\n",
    "print(BigLlama3_1Model[\"cos\"].mean())\n",
    "print(BigLlama3_1Model['levenshtein'].mean())\n",
    "print(BigLlama3_1Model['inv_levenshtein'].mean())\n",
    "print(BigLlama3_1Model['overall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARMEN-I_CC_1.txt\n",
      "Folder 'data/anon/raw/Sonet3_5Model' created successfully\n",
      "1.0\n",
      "0.9375\n",
      "0.967741935483871\n",
      "CARMEN-I_CC_2.txt\n",
      "0.9523809523809523\n",
      "1.0\n",
      "0.975609756097561\n",
      "CARMEN-I_CC_3.txt\n",
      "0.6\n",
      "1.0\n",
      "0.7499999999999999\n",
      "CARMEN-I_CC_4.txt\n",
      "1.0\n",
      "0.9473684210526315\n",
      "0.972972972972973\n",
      "CARMEN-I_CC_5.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_1.txt\n",
      "0.8823529411764706\n",
      "0.9375\n",
      "0.9090909090909091\n",
      "CARMEN-I_IA_ANTECEDENTES_10.txt\n",
      "0.7777777777777778\n",
      "1.0\n",
      "0.8750000000000001\n",
      "CARMEN-I_IA_ANTECEDENTES_100.txt\n",
      "0.8333333333333334\n",
      "0.9090909090909091\n",
      "0.8695652173913043\n",
      "CARMEN-I_IA_ANTECEDENTES_101.txt\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "CARMEN-I_IA_ANTECEDENTES_102.txt\n",
      "0.9583333333333334\n",
      "0.92\n",
      "0.9387755102040817\n",
      "CARMEN-I_IA_ANTECEDENTES_103.txt\n",
      "0.6666666666666666\n",
      "0.8571428571428571\n",
      "0.75\n",
      "CARMEN-I_IA_ANTECEDENTES_104.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_105.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_106.txt\n",
      "0.875\n",
      "1.0\n",
      "0.9333333333333333\n",
      "CARMEN-I_IA_ANTECEDENTES_107.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_108.txt\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.8\n",
      "CARMEN-I_IA_ANTECEDENTES_109.txt\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "CARMEN-I_IA_ANTECEDENTES_11.txt\n",
      "0.36363636363636365\n",
      "1.0\n",
      "0.5333333333333333\n",
      "CARMEN-I_IA_ANTECEDENTES_110.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_111.txt\n",
      "0.7692307692307693\n",
      "0.8333333333333334\n",
      "0.8\n",
      "CARMEN-I_IA_ANTECEDENTES_112.txt\n",
      "0.7857142857142857\n",
      "0.9166666666666666\n",
      "0.8461538461538461\n",
      "CARMEN-I_IA_ANTECEDENTES_113.txt\n",
      "0.8823529411764706\n",
      "1.0\n",
      "0.9375\n",
      "CARMEN-I_IA_ANTECEDENTES_114.txt\n",
      "0.7\n",
      "1.0\n",
      "0.8235294117647058\n",
      "CARMEN-I_IA_ANTECEDENTES_115.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_116.txt\n",
      "0.9166666666666666\n",
      "1.0\n",
      "0.9565217391304348\n",
      "CARMEN-I_IA_ANTECEDENTES_117.txt\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.8\n",
      "CARMEN-I_IA_ANTECEDENTES_118.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_119.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_12.txt\n",
      "0.7931034482758621\n",
      "0.8518518518518519\n",
      "0.8214285714285715\n",
      "CARMEN-I_IA_ANTECEDENTES_120.txt\n",
      "0.8421052631578947\n",
      "1.0\n",
      "0.9142857142857143\n",
      "CARMEN-I_IA_ANTECEDENTES_121.txt\n",
      "0.9\n",
      "1.0\n",
      "0.9473684210526316\n",
      "CARMEN-I_IA_ANTECEDENTES_122.txt\n",
      "0.5714285714285714\n",
      "0.8\n",
      "0.6666666666666666\n",
      "CARMEN-I_IA_ANTECEDENTES_123.txt\n",
      "0.7272727272727273\n",
      "1.0\n",
      "0.8421052631578948\n",
      "CARMEN-I_IA_ANTECEDENTES_124.txt\n",
      "0.9047619047619048\n",
      "0.95\n",
      "0.9268292682926829\n",
      "CARMEN-I_IA_ANTECEDENTES_125.txt\n",
      "0.9333333333333333\n",
      "1.0\n",
      "0.9655172413793104\n",
      "CARMEN-I_IA_ANTECEDENTES_126.txt\n",
      "0.5\n",
      "1.0\n",
      "0.6666666666666666\n",
      "CARMEN-I_IA_ANTECEDENTES_127.txt\n",
      "0.9166666666666666\n",
      "0.9565217391304348\n",
      "0.9361702127659574\n",
      "CARMEN-I_IA_ANTECEDENTES_128.txt\n",
      "0.5294117647058824\n",
      "0.6923076923076923\n",
      "0.5999999999999999\n",
      "CARMEN-I_IA_ANTECEDENTES_129.txt\n",
      "0.8666666666666667\n",
      "0.9285714285714286\n",
      "0.896551724137931\n",
      "CARMEN-I_IA_ANTECEDENTES_13.txt\n",
      "0.875\n",
      "1.0\n",
      "0.9333333333333333\n",
      "CARMEN-I_IA_ANTECEDENTES_130.txt\n",
      "0.8695652173913043\n",
      "1.0\n",
      "0.9302325581395349\n",
      "CARMEN-I_IA_ANTECEDENTES_131.txt\n",
      "0.9545454545454546\n",
      "1.0\n",
      "0.9767441860465117\n",
      "CARMEN-I_IA_ANTECEDENTES_132.txt\n",
      "0.9285714285714286\n",
      "1.0\n",
      "0.962962962962963\n",
      "CARMEN-I_IA_ANTECEDENTES_133.txt\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.8\n",
      "CARMEN-I_IA_ANTECEDENTES_134.txt\n",
      "0.7368421052631579\n",
      "0.875\n",
      "0.7999999999999999\n",
      "CARMEN-I_IA_ANTECEDENTES_135.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_136.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_137.txt\n",
      "0.7857142857142857\n",
      "0.8461538461538461\n",
      "0.8148148148148148\n",
      "CARMEN-I_IA_ANTECEDENTES_138.txt\n",
      "0.7435897435897436\n",
      "0.90625\n",
      "0.8169014084507042\n",
      "CARMEN-I_IA_ANTECEDENTES_14.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_140.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_141.txt\n",
      "0.8421052631578947\n",
      "0.8888888888888888\n",
      "0.8648648648648649\n",
      "CARMEN-I_IA_ANTECEDENTES_15.txt\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "CARMEN-I_IA_ANTECEDENTES_16.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_17.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_18.txt\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "CARMEN-I_IA_ANTECEDENTES_19.txt\n",
      "0.8823529411764706\n",
      "1.0\n",
      "0.9375\n",
      "CARMEN-I_IA_ANTECEDENTES_2.txt\n",
      "0.9444444444444444\n",
      "0.8947368421052632\n",
      "0.918918918918919\n",
      "CARMEN-I_IA_ANTECEDENTES_20.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_21.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_22.txt\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "CARMEN-I_IA_ANTECEDENTES_23.txt\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "CARMEN-I_IA_ANTECEDENTES_24.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_25.txt\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.8\n",
      "CARMEN-I_IA_ANTECEDENTES_26.txt\n",
      "0.9523809523809523\n",
      "1.0\n",
      "0.975609756097561\n",
      "CARMEN-I_IA_ANTECEDENTES_27.txt\n",
      "0.9166666666666666\n",
      "1.0\n",
      "0.9565217391304348\n",
      "CARMEN-I_IA_ANTECEDENTES_28.txt\n",
      "0.8333333333333334\n",
      "0.625\n",
      "0.7142857142857143\n",
      "CARMEN-I_IA_ANTECEDENTES_29.txt\n",
      "0.35294117647058826\n",
      "0.5\n",
      "0.41379310344827586\n",
      "CARMEN-I_IA_ANTECEDENTES_3.txt\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.8\n",
      "CARMEN-I_IA_ANTECEDENTES_30.txt\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "CARMEN-I_IA_ANTECEDENTES_31.txt\n",
      "0.9166666666666666\n",
      "1.0\n",
      "0.9565217391304348\n",
      "CARMEN-I_IA_ANTECEDENTES_32.txt\n",
      "0.8928571428571429\n",
      "0.9615384615384616\n",
      "0.9259259259259259\n",
      "CARMEN-I_IA_ANTECEDENTES_33.txt\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "CARMEN-I_IA_ANTECEDENTES_34.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_35.txt\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "CARMEN-I_IA_ANTECEDENTES_36.txt\n",
      "0.7647058823529411\n",
      "1.0\n",
      "0.8666666666666666\n",
      "CARMEN-I_IA_ANTECEDENTES_37.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_38.txt\n",
      "0.8\n",
      "1.0\n",
      "0.888888888888889\n",
      "CARMEN-I_IA_ANTECEDENTES_4.txt\n",
      "0.9\n",
      "1.0\n",
      "0.9473684210526316\n",
      "CARMEN-I_IA_ANTECEDENTES_40.txt\n",
      "0.875\n",
      "1.0\n",
      "0.9333333333333333\n",
      "CARMEN-I_IA_ANTECEDENTES_41.txt\n",
      "0.9393939393939394\n",
      "1.0\n",
      "0.96875\n",
      "CARMEN-I_IA_ANTECEDENTES_42.txt\n",
      "0.9285714285714286\n",
      "1.0\n",
      "0.962962962962963\n",
      "CARMEN-I_IA_ANTECEDENTES_43.txt\n",
      "0.9230769230769231\n",
      "0.9230769230769231\n",
      "0.9230769230769231\n",
      "CARMEN-I_IA_ANTECEDENTES_44.txt\n",
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "CARMEN-I_IA_ANTECEDENTES_45.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_46.txt\n",
      "0.7692307692307693\n",
      "1.0\n",
      "0.8695652173913044\n",
      "CARMEN-I_IA_ANTECEDENTES_47.txt\n",
      "0.8461538461538461\n",
      "0.9166666666666666\n",
      "0.8799999999999999\n",
      "CARMEN-I_IA_ANTECEDENTES_48.txt\n",
      "0.6\n",
      "1.0\n",
      "0.7499999999999999\n",
      "CARMEN-I_IA_ANTECEDENTES_49.txt\n",
      "0.9411764705882353\n",
      "0.9411764705882353\n",
      "0.9411764705882353\n",
      "CARMEN-I_IA_ANTECEDENTES_5.txt\n",
      "0.8275862068965517\n",
      "1.0\n",
      "0.9056603773584906\n",
      "CARMEN-I_IA_ANTECEDENTES_50.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_51.txt\n",
      "0.8666666666666667\n",
      "0.8125\n",
      "0.8387096774193549\n",
      "CARMEN-I_IA_ANTECEDENTES_52.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_53.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_54.txt\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "CARMEN-I_IA_ANTECEDENTES_55.txt\n",
      "0.9285714285714286\n",
      "1.0\n",
      "0.962962962962963\n",
      "CARMEN-I_IA_ANTECEDENTES_57.txt\n",
      "0.7777777777777778\n",
      "1.0\n",
      "0.8750000000000001\n",
      "CARMEN-I_IA_ANTECEDENTES_58.txt\n",
      "0.9230769230769231\n",
      "1.0\n",
      "0.9600000000000001\n",
      "CARMEN-I_IA_ANTECEDENTES_59.txt\n",
      "0.5\n",
      "1.0\n",
      "0.6666666666666666\n",
      "CARMEN-I_IA_ANTECEDENTES_6.txt\n",
      "0.8461538461538461\n",
      "0.8461538461538461\n",
      "0.8461538461538461\n",
      "CARMEN-I_IA_ANTECEDENTES_60.txt\n",
      "1.0\n",
      "0.95\n",
      "0.9743589743589743\n"
     ]
    }
   ],
   "source": [
    "from llm.strategy.sonet3_5_model import Sonet3_5Model\n",
    "\n",
    "anonimized(llm=Sonet3_5Model(), name_model=\"Sonet3_5Model\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARMEN-I_CC_1.txt\n",
      "Folder 'data/anon/raw/OpusModel' created successfully\n",
      "1.0\n",
      "0.9375\n",
      "0.967741935483871\n",
      "CARMEN-I_CC_2.txt\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "CARMEN-I_CC_3.txt\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "CARMEN-I_CC_4.txt\n",
      "0.68\n",
      "0.8947368421052632\n",
      "0.7727272727272727\n",
      "CARMEN-I_CC_5.txt\n",
      "0.7666666666666667\n",
      "1.0\n",
      "0.8679245283018869\n",
      "CARMEN-I_IA_ANTECEDENTES_1.txt\n",
      "0.7894736842105263\n",
      "0.9375\n",
      "0.8571428571428572\n",
      "CARMEN-I_IA_ANTECEDENTES_10.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_100.txt\n",
      "0.85\n",
      "0.7727272727272727\n",
      "0.8095238095238095\n",
      "CARMEN-I_IA_ANTECEDENTES_101.txt\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "CARMEN-I_IA_ANTECEDENTES_102.txt\n",
      "0.8461538461538461\n",
      "0.88\n",
      "0.8627450980392156\n",
      "CARMEN-I_IA_ANTECEDENTES_103.txt\n",
      "0.6666666666666666\n",
      "0.8571428571428571\n",
      "0.75\n",
      "CARMEN-I_IA_ANTECEDENTES_104.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_105.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_106.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_107.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_108.txt\n",
      "0.5\n",
      "1.0\n",
      "0.6666666666666666\n",
      "CARMEN-I_IA_ANTECEDENTES_109.txt\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "CARMEN-I_IA_ANTECEDENTES_11.txt\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.8\n",
      "CARMEN-I_IA_ANTECEDENTES_110.txt\n",
      "0.875\n",
      "0.9333333333333333\n",
      "0.9032258064516129\n",
      "CARMEN-I_IA_ANTECEDENTES_111.txt\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "CARMEN-I_IA_ANTECEDENTES_112.txt\n",
      "0.9166666666666666\n",
      "0.9166666666666666\n",
      "0.9166666666666666\n",
      "CARMEN-I_IA_ANTECEDENTES_113.txt\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "CARMEN-I_IA_ANTECEDENTES_114.txt\n",
      "0.6363636363636364\n",
      "1.0\n",
      "0.7777777777777778\n",
      "CARMEN-I_IA_ANTECEDENTES_115.txt\n",
      "0.8\n",
      "1.0\n",
      "0.888888888888889\n",
      "CARMEN-I_IA_ANTECEDENTES_116.txt\n",
      "0.9166666666666666\n",
      "1.0\n",
      "0.9565217391304348\n",
      "CARMEN-I_IA_ANTECEDENTES_117.txt\n",
      "0.37037037037037035\n",
      "1.0\n",
      "0.5405405405405406\n",
      "CARMEN-I_IA_ANTECEDENTES_118.txt\n",
      "1.0\n",
      "0.8888888888888888\n",
      "0.9411764705882353\n",
      "CARMEN-I_IA_ANTECEDENTES_119.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_12.txt\n",
      "Read timeout on endpoint URL: \"https://bedrock-runtime.us-west-2.amazonaws.com/model/anthropic.claude-3-opus-20240229-v1%3A0/invoke\"\n",
      "CARMEN-I_IA_ANTECEDENTES_120.txt\n",
      "0.7272727272727273\n",
      "1.0\n",
      "0.8421052631578948\n",
      "CARMEN-I_IA_ANTECEDENTES_121.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_122.txt\n",
      "0.5\n",
      "0.8\n",
      "0.6153846153846154\n",
      "CARMEN-I_IA_ANTECEDENTES_123.txt\n",
      "0.47058823529411764\n",
      "1.0\n",
      "0.6399999999999999\n",
      "CARMEN-I_IA_ANTECEDENTES_124.txt\n",
      "0.8636363636363636\n",
      "0.95\n",
      "0.9047619047619048\n",
      "CARMEN-I_IA_ANTECEDENTES_125.txt\n",
      "0.9333333333333333\n",
      "1.0\n",
      "0.9655172413793104\n",
      "CARMEN-I_IA_ANTECEDENTES_126.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_127.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_128.txt\n",
      "0.6923076923076923\n",
      "0.6923076923076923\n",
      "0.6923076923076923\n",
      "CARMEN-I_IA_ANTECEDENTES_129.txt\n",
      "Read timeout on endpoint URL: \"https://bedrock-runtime.us-west-2.amazonaws.com/model/anthropic.claude-3-opus-20240229-v1%3A0/invoke\"\n",
      "CARMEN-I_IA_ANTECEDENTES_13.txt\n",
      "0.7777777777777778\n",
      "1.0\n",
      "0.8750000000000001\n",
      "CARMEN-I_IA_ANTECEDENTES_130.txt\n",
      "0.8695652173913043\n",
      "1.0\n",
      "0.9302325581395349\n",
      "CARMEN-I_IA_ANTECEDENTES_131.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_132.txt\n",
      "0.9285714285714286\n",
      "1.0\n",
      "0.962962962962963\n",
      "CARMEN-I_IA_ANTECEDENTES_133.txt\n",
      "0.8\n",
      "1.0\n",
      "0.888888888888889\n",
      "CARMEN-I_IA_ANTECEDENTES_134.txt\n",
      "0.7777777777777778\n",
      "0.875\n",
      "0.823529411764706\n",
      "CARMEN-I_IA_ANTECEDENTES_135.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_136.txt\n",
      "0.42857142857142855\n",
      "1.0\n",
      "0.6\n",
      "CARMEN-I_IA_ANTECEDENTES_137.txt\n",
      "0.7857142857142857\n",
      "0.8461538461538461\n",
      "0.8148148148148148\n",
      "CARMEN-I_IA_ANTECEDENTES_138.txt\n",
      "0.90625\n",
      "0.90625\n",
      "0.90625\n",
      "CARMEN-I_IA_ANTECEDENTES_14.txt\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "CARMEN-I_IA_ANTECEDENTES_140.txt\n",
      "1.0\n",
      "0.75\n",
      "0.8571428571428571\n",
      "CARMEN-I_IA_ANTECEDENTES_141.txt\n",
      "0.8181818181818182\n",
      "1.0\n",
      "0.9\n",
      "CARMEN-I_IA_ANTECEDENTES_15.txt\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "CARMEN-I_IA_ANTECEDENTES_16.txt\n",
      "0.9166666666666666\n",
      "0.9166666666666666\n",
      "0.9166666666666666\n",
      "CARMEN-I_IA_ANTECEDENTES_17.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_18.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_19.txt\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "CARMEN-I_IA_ANTECEDENTES_2.txt\n",
      "0.9444444444444444\n",
      "0.8947368421052632\n",
      "0.918918918918919\n",
      "CARMEN-I_IA_ANTECEDENTES_20.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_21.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_22.txt\n",
      "0.68\n",
      "0.9444444444444444\n",
      "0.7906976744186047\n",
      "CARMEN-I_IA_ANTECEDENTES_23.txt\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "CARMEN-I_IA_ANTECEDENTES_24.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_25.txt\n",
      "0.625\n",
      "1.0\n",
      "0.7692307692307693\n",
      "CARMEN-I_IA_ANTECEDENTES_26.txt\n",
      "0.9090909090909091\n",
      "1.0\n",
      "0.9523809523809523\n",
      "CARMEN-I_IA_ANTECEDENTES_27.txt\n",
      "0.75\n",
      "0.9545454545454546\n",
      "0.84\n",
      "CARMEN-I_IA_ANTECEDENTES_28.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_29.txt\n",
      "0.3333333333333333\n",
      "0.5\n",
      "0.4\n",
      "CARMEN-I_IA_ANTECEDENTES_3.txt\n",
      "0.4\n",
      "1.0\n",
      "0.5714285714285715\n",
      "CARMEN-I_IA_ANTECEDENTES_30.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_31.txt\n",
      "0.9166666666666666\n",
      "1.0\n",
      "0.9565217391304348\n",
      "CARMEN-I_IA_ANTECEDENTES_32.txt\n",
      "0.8125\n",
      "1.0\n",
      "0.896551724137931\n",
      "CARMEN-I_IA_ANTECEDENTES_33.txt\n",
      "1.0\n",
      "0.8333333333333334\n",
      "0.9090909090909091\n",
      "CARMEN-I_IA_ANTECEDENTES_34.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_35.txt\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "CARMEN-I_IA_ANTECEDENTES_36.txt\n",
      "0.7647058823529411\n",
      "1.0\n",
      "0.8666666666666666\n",
      "CARMEN-I_IA_ANTECEDENTES_37.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_38.txt\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.8\n",
      "CARMEN-I_IA_ANTECEDENTES_4.txt\n",
      "0.8181818181818182\n",
      "1.0\n",
      "0.9\n",
      "CARMEN-I_IA_ANTECEDENTES_40.txt\n",
      "0.875\n",
      "1.0\n",
      "0.9333333333333333\n",
      "CARMEN-I_IA_ANTECEDENTES_41.txt\n",
      "0.9117647058823529\n",
      "1.0\n",
      "0.9538461538461539\n",
      "CARMEN-I_IA_ANTECEDENTES_42.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_43.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_44.txt\n",
      "1.0\n",
      "0.9523809523809523\n",
      "0.975609756097561\n",
      "CARMEN-I_IA_ANTECEDENTES_45.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_46.txt\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "CARMEN-I_IA_ANTECEDENTES_47.txt\n",
      "0.9166666666666666\n",
      "0.9166666666666666\n",
      "0.9166666666666666\n",
      "CARMEN-I_IA_ANTECEDENTES_48.txt\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "CARMEN-I_IA_ANTECEDENTES_49.txt\n",
      "1.0\n",
      "0.9411764705882353\n",
      "0.9696969696969697\n",
      "CARMEN-I_IA_ANTECEDENTES_5.txt\n",
      "Read timeout on endpoint URL: \"https://bedrock-runtime.us-west-2.amazonaws.com/model/anthropic.claude-3-opus-20240229-v1%3A0/invoke\"\n",
      "CARMEN-I_IA_ANTECEDENTES_50.txt\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "CARMEN-I_IA_ANTECEDENTES_51.txt\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "CARMEN-I_IA_ANTECEDENTES_52.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_53.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_54.txt\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "CARMEN-I_IA_ANTECEDENTES_55.txt\n",
      "0.6842105263157895\n",
      "1.0\n",
      "0.8125000000000001\n",
      "CARMEN-I_IA_ANTECEDENTES_57.txt\n",
      "0.875\n",
      "1.0\n",
      "0.9333333333333333\n",
      "CARMEN-I_IA_ANTECEDENTES_58.txt\n",
      "0.7857142857142857\n",
      "0.9166666666666666\n",
      "0.8461538461538461\n",
      "CARMEN-I_IA_ANTECEDENTES_59.txt\n",
      "0.3333333333333333\n",
      "1.0\n",
      "0.5\n",
      "CARMEN-I_IA_ANTECEDENTES_6.txt\n",
      "0.9166666666666666\n",
      "0.8461538461538461\n",
      "0.8799999999999999\n",
      "CARMEN-I_IA_ANTECEDENTES_60.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_61.txt\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "CARMEN-I_IA_ANTECEDENTES_62.txt\n",
      "0.9047619047619048\n",
      "0.95\n",
      "0.9268292682926829\n",
      "CARMEN-I_IA_ANTECEDENTES_63.txt\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CARMEN-I_IA_ANTECEDENTES_64.txt\n",
      "1.0\n",
      "0.75\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "from llm.strategy.opus3_model import OpusModel\n",
    "\n",
    "anonimized(llm=OpusModel(), name_model=\"OpusModel\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.context.llm_context import LLMContext\n",
    "from llm.strategy.big_llama_model import BigLlamaModel\n",
    "from llm.strategy.haiku3_model import Haiku3Model\n",
    "\n",
    "# Big Llama\n",
    "data = {\"system\": \"Lorem ipsum test\", \"user\": \"Lorem ipsum text\"}\n",
    "context = LLMContext(BigLlamaModel())\n",
    "text_generated = context.generate_response(data)\n",
    "\n",
    "# Haiku\n",
    "data = {\"system\": \"Lorem ipsum\", \"user\": \"Lorem ipsum\"}\n",
    "context = LLMContext(Haiku3Model())\n",
    "text_generated = context.generate_response(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 12)\n",
      "0.8535672483191294\n",
      "0.9627737779670088\n",
      "0.8985131509758659\n",
      "0.9994267983558274\n",
      "1.99\n",
      "0.651120879120879\n",
      "4.204708143475926\n"
     ]
    }
   ],
   "source": [
    "Sonet3_5_data = pd.read_csv('./data/metrics/Sonet3_5Model.csv')\n",
    "Sonet3_5_data = Sonet3_5_data[Sonet3_5_data['fail'] != 0]\n",
    "print(Sonet3_5_data.shape)\n",
    "print(Sonet3_5_data[\"precision\"].mean())\n",
    "print(Sonet3_5_data[\"recall\"].mean())\n",
    "print(Sonet3_5_data[\"f1\"].mean())\n",
    "print(Sonet3_5_data[\"cos\"].mean())\n",
    "print(Sonet3_5_data['levenshtein'].mean())\n",
    "print(Sonet3_5_data['inv_levenshtein'].mean())\n",
    "print(Sonet3_5_data['overall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 12)\n",
      "0.844970460044348\n",
      "0.9586331207621069\n",
      "0.8880016797900169\n",
      "0.991238482578299\n",
      "26.88\n",
      "0.4865013165808512\n",
      "3.904609461724178\n"
     ]
    }
   ],
   "source": [
    "OpusModel_data = pd.read_csv('./data/metrics/OpusModel.csv')\n",
    "OpusModel_data = OpusModel_data[OpusModel_data['fail'] != 0]\n",
    "print(OpusModel_data.shape)\n",
    "print(OpusModel_data[\"precision\"].mean())\n",
    "print(OpusModel_data[\"recall\"].mean())\n",
    "print(OpusModel_data[\"f1\"].mean())\n",
    "print(OpusModel_data[\"cos\"].mean())\n",
    "print(OpusModel_data['levenshtein'].mean())\n",
    "print(OpusModel_data['inv_levenshtein'].mean())\n",
    "print(OpusModel_data['overall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
